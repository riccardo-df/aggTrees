<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="aggTrees">
<title>Short Tutorial â€¢ aggTrees</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Short Tutorial">
<meta property="og:description" content="aggTrees">
<meta property="og:image" content="https://riccardo-df.github.io/aggTrees/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">aggTrees</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/aggTrees-vignette.html">Short Tutorial</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Short Tutorial</h1>
            
      
      
      <div class="d-none name"><code>aggTrees-vignette.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h3>
<p>In this tutorial, we show a typical usage of the package. For
illustration purposes, let us generate some data:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Generate data.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1986</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">5000</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">k</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">D</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">mu0</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">mu1</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">mu0</span> <span class="op">+</span> <span class="va">D</span> <span class="op">*</span> <span class="op">(</span><span class="va">mu1</span> <span class="op">-</span> <span class="va">mu0</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="constructing-the-sequence-of-groupings">Constructing the Sequence of Groupings<a class="anchor" aria-label="anchor" href="#constructing-the-sequence-of-groupings"></a>
</h3>
<p>To construct the sequence of optimal groupings, we first need to
estimate the CATEs. Here we use the causal forest estimator. To achieve
valid inference about the GATEs, we split the sample into a training
sample and an honest sample of equal sizes. The forest is built using
only the training sample.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Sample split.</span></span>
<span><span class="va">splits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_split.html">sample_split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, training_frac <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">training_idx</span> <span class="op">&lt;-</span> <span class="va">splits</span><span class="op">$</span><span class="va">training_idx</span></span>
<span><span class="va">honest_idx</span> <span class="op">&lt;-</span> <span class="va">splits</span><span class="op">$</span><span class="va">honest_idx</span></span>
<span></span>
<span><span class="va">y_tr</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">training_idx</span><span class="op">]</span></span>
<span><span class="va">D_tr</span> <span class="op">&lt;-</span> <span class="va">D</span><span class="op">[</span><span class="va">training_idx</span><span class="op">]</span></span>
<span><span class="va">X_tr</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">training_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">y_hon</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">honest_idx</span><span class="op">]</span></span>
<span><span class="va">D_hon</span> <span class="op">&lt;-</span> <span class="va">D</span><span class="op">[</span><span class="va">honest_idx</span><span class="op">]</span></span>
<span><span class="va">X_hon</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">honest_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co">## Estimate the CATEs. Use training sample.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/grf-labs/grf" class="external-link">grf</a></span><span class="op">)</span></span>
<span><span class="va">forest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/grf/man/causal_forest.html" class="external-link">causal_forest</a></span><span class="op">(</span><span class="va">X_tr</span>, <span class="va">y_tr</span>, <span class="va">D_tr</span><span class="op">)</span> </span>
<span><span class="va">cates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">forest</span>, <span class="va">X</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span></span></code></pre></div>
<p>Now we use the <code>build_aggtree</code> function to construct the
sequence of groupings. This function approximates the estimated CATEs by
a decision tree using only the training sample and computes node
predictions (i.e., the GATEs) using only the honest sample.
<code>build_aggtree</code> allows the user to choose between two GATE
estimators:</p>
<ol style="list-style-type: decimal">
<li>If we set <code>method = "raw"</code>, the GATEs are estimated by
taking the differences between the mean outcomes of treated and control
units in each node. This is an unbiased estimator (only) in randomized
experiments;</li>
<li>If we set <code>method = "aipw"</code>, the GATEs are estimated by
averaging doubly-robust scores (see Appendix below) in each node. This
is an unbiased estimator also in observational studies under particular
conditions on the construction of the scores.</li>
</ol>
<p>The doubly-robust scores can be estimated separately and passed in by
the <code>scores</code> argument. Otherwise, they are estimated
internally. Notice the use of the <code>is_honest</code> argument, a
logical vector denoting which observations we allocated to the honest
sample. This way, <code>build_aggtree</code> knows which observations
must be used to construct the tree and compute node predictions.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Construct the sequence. Use doubly-robust scores.</span></span>
<span><span class="va">groupings</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_aggtree.html">build_aggtree</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">D</span>, <span class="va">X</span>, method <span class="op">=</span> <span class="st">"aipw"</span>, </span>
<span>                           cates <span class="op">=</span> <span class="va">cates</span>, is_honest <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">honest_idx</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Print.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">groupings</span><span class="op">)</span></span>
<span><span class="co">#&gt; Honest estimates: TRUE </span></span>
<span><span class="co">#&gt; n= 2500 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1) root 2500 2372.437000  0.04518749  </span></span>
<span><span class="co">#&gt;    2) x2&lt; 0.3646614 1615  614.394700 -0.55084130  </span></span>
<span><span class="co">#&gt;      4) x2&lt; -0.7479499 594   63.762530 -1.31435400  </span></span>
<span><span class="co">#&gt;        8) x2&lt; -1.438649 217    5.703318 -2.03895100 *</span></span>
<span><span class="co">#&gt;        9) x2&gt;=-1.438649 377   13.974630 -0.98914180 *</span></span>
<span><span class="co">#&gt;      5) x2&gt;=-0.7479499 1021   84.592370 -0.14006240  </span></span>
<span><span class="co">#&gt;       10) x2&lt; -0.3224095 345   11.004430 -0.38424370 *</span></span>
<span><span class="co">#&gt;       11) x2&gt;=-0.3224095 676   19.214170 -0.01797179 *</span></span>
<span><span class="co">#&gt;    3) x2&gt;=0.3646614 885  221.380400  1.06528900  </span></span>
<span><span class="co">#&gt;      6) x2&lt; 1.510563 714   58.170860  0.93028800  </span></span>
<span><span class="co">#&gt;       12) x2&lt; 0.7534031 301    7.964079  0.56146550 *</span></span>
<span><span class="co">#&gt;       13) x2&gt;=0.7534031 413    8.017662  1.22245000 *</span></span>
<span><span class="co">#&gt;      7) x2&gt;=1.510563 171   10.190770  1.78282800 *</span></span>
<span></span>
<span><span class="co">## Plot.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">groupings</span><span class="op">)</span> <span class="co"># Try also setting 'sequence = TRUE'.</span></span></code></pre></div>
<p><img src="aggTrees-vignette_files/figure-html/construct-sequence-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="further-analysis">Further Analysis<a class="anchor" aria-label="anchor" href="#further-analysis"></a>
</h3>
<p>Now that we have a whole sequence of optimal groupings, we can pick
the grouping associated with our preferred granularity level and call
the <code>inference_aggtree</code> function. This function does the
following:</p>
<ol style="list-style-type: decimal">
<li>It gets standard errors for the GATEs by estimating via OLS
appropriate linear models using the honest sample. The choice of the
linear model depends on the <code>method</code> we used when we called
<code>build_aggtree</code> (see Appendix below);</li>
<li>It tests the null hypotheses that the differences in the GATEs
across all pairs of groups equal zero. Here, we account for multiple
hypotheses testing by adjusting the <span class="math inline">\(p\)</span>-values using Holmâ€™s procedure;</li>
<li>It computes the average characteristics of the units in each
group.</li>
</ol>
<p>To report the results, we can print nice LATEX tables.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Inference with 4 groups.</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_aggtree.html">inference_aggtree</a></span><span class="op">(</span><span class="va">groupings</span>, n_groups <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## LATEX.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span>, table <span class="op">=</span> <span class="st">"diff"</span><span class="op">)</span></span>
<span><span class="co">#&gt; \begingroup</span></span>
<span><span class="co">#&gt;   \setlength{\tabcolsep}{8pt}</span></span>
<span><span class="co">#&gt;   \renewcommand{\arraystretch}{1.2}</span></span>
<span><span class="co">#&gt;   \begin{table}[b!]</span></span>
<span><span class="co">#&gt;     \centering</span></span>
<span><span class="co">#&gt;     \begin{adjustbox}{width = 0.85\textwidth}</span></span>
<span><span class="co">#&gt;     \begin{tabular}{@{\extracolsep{5pt}}l c c c c}</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       &amp; \textit{Leaf 1} &amp; \textit{Leaf 2} &amp; \textit{Leaf 3} &amp; \textit{Leaf 4} \\</span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \multirow{2}{*}{GATEs} &amp; -1.314 &amp; -0.14 &amp; 0.93 &amp; 1.783 \\</span></span>
<span><span class="co">#&gt;       &amp; [-1.49, -1.138] &amp; [-0.262, -0.018] &amp; [0.783, 1.077] &amp; [1.487, 2.079] \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \textit{Leaf 1} &amp; NA &amp; NA &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (NA) &amp; (NA) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 2} &amp; 1.174 &amp; NA &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (NA) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 3} &amp; 2.245 &amp; 1.07 &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (0) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 4} &amp; 3.097 &amp; 1.923 &amp; 0.853 &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (0) &amp; (0) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[3pt]</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;     \end{tabular}</span></span>
<span><span class="co">#&gt;     \end{adjustbox}</span></span>
<span><span class="co">#&gt;     \caption{Point estimates and $95\%$ confidence intervals for the GATEs. Leaves are sorted in increasing order of the GATEs. Additionally, differences in the GATEs across all pairs of leaves are displayed. p-values to test the null hypothesis that a single difference is zero are adjusted using Holm's procedure and reported in parenthesis under each point estimate.}</span></span>
<span><span class="co">#&gt;     \label{table:differences.gates}</span></span>
<span><span class="co">#&gt;     \end{table}</span></span>
<span><span class="co">#&gt; \endgroup</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span>, table <span class="op">=</span> <span class="st">"avg_char"</span><span class="op">)</span></span>
<span><span class="co">#&gt; \begingroup</span></span>
<span><span class="co">#&gt;   \setlength{\tabcolsep}{8pt}</span></span>
<span><span class="co">#&gt;   \renewcommand{\arraystretch}{1.1}</span></span>
<span><span class="co">#&gt;   \begin{table}[b!]</span></span>
<span><span class="co">#&gt;     \centering</span></span>
<span><span class="co">#&gt;     \begin{adjustbox}{width = 1\textwidth}</span></span>
<span><span class="co">#&gt;     \begin{tabular}{@{\extracolsep{5pt}}l c c c c c c c c }</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;       &amp; \multicolumn{2}{c}{\textit{Leaf 1}} &amp; \multicolumn{2}{c}{\textit{Leaf 2}} &amp; \multicolumn{2}{c}{\textit{Leaf 3}} &amp; \multicolumn{2}{c}{\textit{Leaf 4}} \\\cmidrule{2-3} \cmidrule{4-5} \cmidrule{6-7} \cmidrule{8-9} </span></span>
<span><span class="co">#&gt;       &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) \\</span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \texttt{x1} &amp; 0.047 &amp; (0.04) &amp; -0.019 &amp; (0.03) &amp; 0.006 &amp; (0.036) &amp; -0.024 &amp; (0.087) \\ </span></span>
<span><span class="co">#&gt;       \texttt{x2} &amp; -1.309 &amp; (0.021) &amp; -0.161 &amp; (0.01) &amp; 0.854 &amp; (0.012) &amp; 1.933 &amp; (0.033) \\ </span></span>
<span><span class="co">#&gt;       \texttt{x3} &amp; 0.053 &amp; (0.042) &amp; -0.016 &amp; (0.03) &amp; 0.031 &amp; (0.037) &amp; 0.041 &amp; (0.079) \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[3pt]</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;     \end{tabular}</span></span>
<span><span class="co">#&gt;     \end{adjustbox}</span></span>
<span><span class="co">#&gt;     \caption{Average characteristics of units in each leaf, obtained by regressing each covariate on a set of dummies denoting leaf membership. Standard errors are estimated via the Eicker-Huber-White estimator. Leaves are sorted in increasing order of the GATEs.}</span></span>
<span><span class="co">#&gt;     \label{table:average.characteristics.leaves}</span></span>
<span><span class="co">#&gt;     \end{table}</span></span>
<span><span class="co">#&gt; \endgroup</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="appendix">Appendix<a class="anchor" aria-label="anchor" href="#appendix"></a>
</h3>
<p>The point of estimating the linear models is to get standard errors
for the GATEs. Under an honesty condition, we can use the estimated
standard errors to conduct valid inference as usual, e.g., by
constructing conventional confidence intervals. Honesty is a
subsample-splitting technique that requires that different observations
are used to form the subgroups and estimate the GATEs.
<code>inference_aggtree</code> always uses the honest sample to estimate
the linear models below (unless we called <code>build_aggtree</code>
without using the honesty settings).</p>
<p>If we set <code>method = "raw"</code>, <code>inference_aggtree</code>
estimates via OLS the following linear model:</p>
<p><span class="math display">\[\begin{equation}
    Y_i = \sum_{l = 1}^{|\mathcal{T_{\alpha}}|} L_{i, l} \, \gamma_l +
\sum_{l = 1}^{|\mathcal{T}_{\alpha}|} L_{i, l} \, D_i \, \beta_l +
\epsilon_i
\end{equation}\]</span></p>
<p>with <span class="math inline">\(|\mathcal{T}_{\alpha}|\)</span> the
number of leaves of a particular tree <span class="math inline">\(\mathcal{T}_{\alpha}\)</span>, and <span class="math inline">\(L_{i, l}\)</span> a dummy variable equal to one if
the <span class="math inline">\(i\)</span>-th unit falls in the <span class="math inline">\(l\)</span>-th leaf of <span class="math inline">\(\mathcal{T}_{\alpha}\)</span>. Exploiting the
random assignment to treatment, we can show that each <span class="math inline">\(\beta_l\)</span> identifies the GATE in the <span class="math inline">\(l\)</span>-th leaf. Under honesty, the OLS
estimator <span class="math inline">\(\hat{\beta}_l\)</span> of <span class="math inline">\(\beta_l\)</span> is root-<span class="math inline">\(n\)</span> consistent and asymptotically
normal.</p>
<p>If we set <code>method = "aipw"</code>,
<code>inference_aggtree</code> estimates via OLS the following linear
model:</p>
<p><span class="math display">\[\begin{equation}
    \widehat{\Gamma}_i = \sum_{l = 1}^{|\mathcal{T}_{\alpha}|} L_{i, l}
\, \beta_l + \epsilon_i
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\Gamma_i\)</span> are the following
doubly-robust scores:</p>
<p><span class="math display">\[\begin{equation*}
    \Gamma_i = \mu \left( 1, X_i \right) - \mu \left( 0, X_i \right) +
\frac{D_i \left[ Y_i - \mu \left( 1, X_i \right) \right]}{p \left( X_i
\right)}  - \frac{ \left( 1 - D_i \right) \left[ Y_i - \mu \left( 0, X_i
\right) \right]}{1 - p \left( X_i \right)}
\end{equation*}\]</span></p>
<p>with <span class="math inline">\(\mu \left(D_i, X_i \right) =
\mathbb{E} \left[ Y_i | D_i, Z_i \right]\)</span> the conditional mean
of <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(p \left( X_i \right) = \mathbb{P} \left( D_i = 1 |
X_i \right)\)</span> the propensity score. These scores are inherited by
the scores used in the <code>build_aggtree</code> call. As before, we
can show that each <span class="math inline">\(\beta_l\)</span>
identifies the GATE in the <span class="math inline">\(l\)</span>-th
leaf, this time even in observational studies. Under honesty, the OLS
estimator <span class="math inline">\(\hat{\beta}_l\)</span> of <span class="math inline">\(\beta_l\)</span> is root-<span class="math inline">\(n\)</span> consistent and asymptotically normal,
provided that the <span class="math inline">\(\Gamma_i\)</span> are
cross-fitted and that the product of the convergence rates of the
estimators of the nuisance functions <span class="math inline">\(\mu
\left( \cdot, \cdot \right)\)</span> and <span class="math inline">\(p
\left( \cdot \right)\)</span> is faster than <span class="math inline">\(n^{1/2}\)</span>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Riccardo Di Francesco.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
