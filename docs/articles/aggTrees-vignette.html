<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="aggTrees">
<title>Aggregation Trees • aggTrees</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Aggregation Trees">
<meta property="og:description" content="aggTrees">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">aggTrees</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/aggTrees-vignette.html">Aggregation Trees</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Aggregation Trees</h1>
                        <h4 data-toc-skip class="author">Riccardo Di
Francesco</h4>
            
      
      
      <div class="d-none name"><code>aggTrees-vignette.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>R package to implement aggregation trees, a nonparametric approach to
discovering heterogeneous subgroups in a selection-on-observables
framework.</p>
<p>The approach consists of three steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate the conditional average treatment effects (CATEs);</li>
<li>Approximate the CATEs by a decision tree;</li>
<li>Prune the tree.</li>
</ol>
<p>This way, we generate a sequence of groupings, one for each
granularity level. The resulting sequence is nested in the sense that
subgroups formed at a given level of granularity are never broken at
coarser levels. This guarantees consistency of the results across the
different granularity levels, generally considered a basic requirement
that every classification system should satisfy. Moreover, each grouping
features an optimality property in that it ensures that the loss in
explained heterogeneity resulting from aggregation is minimized.</p>
<p>Given the sequence of groupings, we can pick a particular granularity
level and estimate the group average treatment effects (GATEs). In
randomized experiments, an unbiased GATE estimator consists of taking
the difference between the mean outcomes of treated and control units in
each group. Equivalently, we can obtain the same point estimates in
addition to their standard errors by estimating via OLS the following
linear model:</p>
<p><span class="math display">\[\begin{equation}
    Y_i = \sum_{l = 1}^{|\mathcal{T_{\alpha}}|} L_{i, l} \, \gamma_l +
\sum_{l = 1}^{|\mathcal{T}_{\alpha}|} L_{i, l} \, D_i \, \beta_l +
\epsilon_i
\end{equation}\]</span></p>
<p>with <span class="math inline">\(|\mathcal{T}_{\alpha}|\)</span> the
number of leaves of a particular tree <span class="math inline">\(\mathcal{T}_{\alpha}\)</span>, and <span class="math inline">\(L_{i, l}\)</span> a dummy variable equal to one if
the <span class="math inline">\(i\)</span>-th unit falls in the <span class="math inline">\(l\)</span>-th leaf of <span class="math inline">\(\mathcal{T}_{\alpha}\)</span>. Exploiting the
random assignment to treatment, we can show that each <span class="math inline">\(\beta_l\)</span> identifies the GATE in the <span class="math inline">\(l\)</span>-th leaf.</p>
<p>However, in observational studies this estimator is biased due to the
selection into treatment. To get unbiased estimates, we can construct
via <span class="math inline">\(K\)</span>-fold cross-fitting the
following doubly-robust scores:</p>
<p><span class="math display">\[\begin{equation*}
    \Gamma_i = \mu \left( 1, X_i \right) - \mu \left( 0, X_i \right) +
\frac{D_i \left[ Y_i - \mu \left( 1, X_i \right) \right]}{p \left( X_i
\right)}  - \frac{ \left( 1 - D_i \right) \left[ Y_i - \mu \left( 0, X_i
\right) \right]}{1 - p \left( X_i \right)}
\end{equation*}\]</span></p>
<p>where <span class="math inline">\(\mu \left(D_i, X_i \right) =
\mathbb{E} \left[ Y_i | D_i, Z_i \right]\)</span> is the conditional
mean of <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(p \left( X_i \right) = \mathbb{P} \left( D_i = 1 |
X_i \right)\)</span> is the propensity score. Consider the following
linear model:</p>
<p><span class="math display">\[\begin{equation}
    \widehat{\Gamma}_i = \sum_{l = 1}^{|\mathcal{T}_{\alpha}|} L_{i, l}
\, \beta_l + \epsilon_i
\end{equation}\]</span></p>
<p>As before, we can show that each <span class="math inline">\(\beta_l\)</span> identifies the GATE in the <span class="math inline">\(l\)</span>-th leaf, this time even in
observational studies. Importantly, the OLS estimator <span class="math inline">\(\hat{\beta}_l\)</span> of <span class="math inline">\(\beta_l\)</span> is root-<span class="math inline">\(n\)</span> consistent and asymptotically normal,
provided that the product of the convergence rates of the estimators of
the nuisance functions <span class="math inline">\(\mu \left( \cdot,
\cdot \right)\)</span> and <span class="math inline">\(p \left( \cdot
\right)\)</span> is faster than <span class="math inline">\(n^{1/2}\)</span>.</p>
<p>However, GATE estimates may show some bias if we use the same data to
construct the tree and to estimate the models above, leading to invalid
inference. One way out is to grow “honest” aggregation trees. Honesty is
a subsample-splitting technique that requires that different
observations are used to form the subgroups and estimate the GATEs. For
this purpose, we split the observed sample into a training sample <span class="math inline">\(\mathcal{S}^{tr}\)</span> and an honest sample
<span class="math inline">\(\mathcal{S}^{hon}\)</span> of arbitrary
sizes. We use <span class="math inline">\(\mathcal{S}^{tr}\)</span> to
estimate the CATEs and construct the tree and, for a particular grouping
<span class="math inline">\(\mathcal{T}_{\alpha}\)</span>, we use <span class="math inline">\(\mathcal{S}^{hon}\)</span> to estimate the models
above. This way, the asymptotic properties of the estimators discussed
above are the same as if the groupings had been exogenously given. This
allows us to use the estimated standard errors to conduct inference
about the GATEs using standard methods, e.g., by constructing
conventional confidence intervals.</p>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>The package can be downloaded from CRAN:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"aggTrees"</span><span class="op">)</span></span></code></pre></div>
<p>Alternatively, the current development version of the package can be
installed using the <code>devtools</code> package:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"riccardo-df/aggTrees"</span><span class="op">)</span> <span class="co"># run install.packages("devtools") if needed.</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="usage-examples">Usage Examples<a class="anchor" aria-label="anchor" href="#usage-examples"></a>
</h2>
<p>This section demonstrates how to use the package. Let us generate
some data:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Generate data.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1986</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">5000</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">k</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">D</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">mu0</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">mu1</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">mu0</span> <span class="op">+</span> <span class="va">D</span> <span class="op">*</span> <span class="op">(</span><span class="va">mu1</span> <span class="op">-</span> <span class="va">mu0</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="constructing-the-sequence-of-groupings">Constructing the Sequence of Groupings<a class="anchor" aria-label="anchor" href="#constructing-the-sequence-of-groupings"></a>
</h3>
<p>The <code>build_aggtree</code> function can be used to construct the
sequence of groupings. This function estimates the CATEs internally via
a <a href="https://github.com/grf-labs/grf/blob/master/r-package/grf/R/causal_forest.R" class="external-link">causal
forest</a> and approximates them by a decision tree. Then, it computes
node predictions (i.e., the GATEs) by either taking the difference
between the mean outcomes of treated and control units in each node or
constructing and averaging doubly-robust scores, according to the
<code>method</code> argument. By default, <code>build_aggtree</code>
implements honesty.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Construct sequence of groupings. CATEs estimated internally.</span></span>
<span><span class="va">groupings</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_aggtree.html">build_aggtree</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">D</span>, <span class="va">X</span>, method <span class="op">=</span> <span class="st">"aipw"</span><span class="op">)</span> <span class="co"># We set 'method = "aipw"' to construct and average doubly-robust scores.</span></span>
<span></span>
<span><span class="co">## Print.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">groupings</span><span class="op">)</span></span>
<span><span class="co">#&gt; Honest estimates: TRUE </span></span>
<span><span class="co">#&gt; n= 2500 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  1) root 2500 2380.264000  0.045018990  </span></span>
<span><span class="co">#&gt;    2) x2&lt; 0.4111544 1654  623.407600 -0.529343000  </span></span>
<span><span class="co">#&gt;      4) x2&lt; -0.7479499 594   61.023280 -1.313696000  </span></span>
<span><span class="co">#&gt;        8) x2&lt; -1.40893 224    3.623873 -1.929331000 *</span></span>
<span><span class="co">#&gt;        9) x2&gt;=-1.40893 370   11.294270 -1.003363000 *</span></span>
<span><span class="co">#&gt;      5) x2&gt;=-0.7479499 1060   82.638300 -0.120887400  </span></span>
<span><span class="co">#&gt;       10) x2&lt; -0.3224095 345    8.867871 -0.380943400 *</span></span>
<span><span class="co">#&gt;       11) x2&gt;=-0.3224095 715   16.486690  0.002983327 *</span></span>
<span><span class="co">#&gt;    3) x2&gt;=0.4111544 846  199.306000  1.087667000  </span></span>
<span><span class="co">#&gt;      6) x2&lt; 1.534637 682   43.075580  0.961647100  </span></span>
<span><span class="co">#&gt;       12) x2&lt; 0.7833315 280    3.750833  0.583637500 *</span></span>
<span><span class="co">#&gt;       13) x2&gt;=0.7833315 402    6.551331  1.261884000 *</span></span>
<span><span class="co">#&gt;      7) x2&gt;=1.534637 164    4.632625  1.772559000 *</span></span>
<span></span>
<span><span class="co">## Plot.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">groupings</span><span class="op">)</span> <span class="co"># Try also setting 'sequence = TRUE'.</span></span></code></pre></div>
<p><img src="aggTrees-vignette_files/figure-html/construct-sequence-1.png" width="700"></p>
<p>To use a different CATE estimator, we can use the <code>cates</code>
argument. When this is the case, we also need to specify
<code>is_honest</code>, a logical vector denoting which observations we
allocated to the honest sample. This way, <code>build_aggtree</code>
knows which observations must be used to construct the tree and compute
node predictions.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Estimate the CATEs.</span></span>
<span><span class="va">splits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sample_split.html">sample_split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, training_frac <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">training_idx</span> <span class="op">&lt;-</span> <span class="va">splits</span><span class="op">$</span><span class="va">training_idx</span></span>
<span><span class="va">honest_idx</span> <span class="op">&lt;-</span> <span class="va">splits</span><span class="op">$</span><span class="va">honest_idx</span></span>
<span></span>
<span><span class="va">y_tr</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">training_idx</span><span class="op">]</span></span>
<span><span class="va">D_tr</span> <span class="op">&lt;-</span> <span class="va">D</span><span class="op">[</span><span class="va">training_idx</span><span class="op">]</span></span>
<span><span class="va">X_tr</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">training_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">y_hon</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">honest_idx</span><span class="op">]</span></span>
<span><span class="va">D_hon</span> <span class="op">&lt;-</span> <span class="va">D</span><span class="op">[</span><span class="va">honest_idx</span><span class="op">]</span></span>
<span><span class="va">X_hon</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">honest_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/grf-labs/grf" class="external-link">grf</a></span><span class="op">)</span></span>
<span><span class="va">forest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/grf/man/causal_forest.html" class="external-link">causal_forest</a></span><span class="op">(</span><span class="va">X_tr</span>, <span class="va">y_tr</span>, <span class="va">D_tr</span><span class="op">)</span> <span class="co"># Use training sample.</span></span>
<span><span class="va">cates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">forest</span>, <span class="va">X</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span></span>
<span></span>
<span><span class="co">## Use the arguments 'cates' and 'is_honest'.</span></span>
<span><span class="va">groupings</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_aggtree.html">build_aggtree</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">D</span>, <span class="va">X</span>, method <span class="op">=</span> <span class="st">"aipw"</span>, </span>
<span>                           cates <span class="op">=</span> <span class="va">cates</span>, is_honest <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">honest_idx</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="gates-estimation-and-inference">GATEs Estimation and Inference<a class="anchor" aria-label="anchor" href="#gates-estimation-and-inference"></a>
</h3>
<p>Now we have a whole sequence of optimal groupings. We can pick the
grouping associated with our preferred granularity level and run some
analysis. First, we would like to get standard errors for the GATEs.
This is achieved by estimating via OLS appropriate linear models using
the honest sample (see the Introduction above). Then, we can assess
whether we find systematic heterogeneity by testing a bunch of
hypotheses. For example, we can use the standard errors to test the
hypotheses that the differences in the GATEs across all pairs of leaves
equal zero. If evidence of heterogeneity is found, we can investigate
the mechanisms behind by computing the average characteristics of the
units in each group. All of this is done by the
<code>inference_aggtree</code> function.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Inference with 4 groups.</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/build_aggtree.html">inference_aggtree</a></span><span class="op">(</span><span class="va">groupings</span>, n_groups <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<p>To help the user report the results, the package allows us to print
nice LATEX tables.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span>, table <span class="op">=</span> <span class="st">"diff"</span><span class="op">)</span></span>
<span><span class="co">#&gt; \begingroup</span></span>
<span><span class="co">#&gt;   \setlength{\tabcolsep}{8pt}</span></span>
<span><span class="co">#&gt;   \renewcommand{\arraystretch}{1.2}</span></span>
<span><span class="co">#&gt;   \begin{table}[b!]</span></span>
<span><span class="co">#&gt;     \centering</span></span>
<span><span class="co">#&gt;     \begin{adjustbox}{width = 0.85\textwidth}</span></span>
<span><span class="co">#&gt;     \begin{tabular}{@{\extracolsep{5pt}}l c c c c}</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       &amp; \textit{Leaf 1} &amp; \textit{Leaf 2} &amp; \textit{Leaf 3} &amp; \textit{Leaf 4} \\</span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \multirow{2}{*}{GATEs} &amp; -1.419 &amp; -0.174 &amp; 0.778 &amp; 1.506 \\</span></span>
<span><span class="co">#&gt;       &amp; [-1.597, -1.241] &amp; [-0.294, -0.054] &amp; [0.606, 0.95] &amp; [1.267, 1.745] \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \textit{Leaf 1} &amp; NA &amp; NA &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (NA) &amp; (NA) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 2} &amp; 1.245 &amp; NA &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (NA) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 3} &amp; 2.197 &amp; 0.952 &amp; NA &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (0) &amp; (NA) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt;       \textit{Leaf 4} &amp; 2.925 &amp; 1.681 &amp; 0.729 &amp; NA \\</span></span>
<span><span class="co">#&gt;             &amp; (0) &amp; (0) &amp; (0) &amp; (NA) \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[3pt]</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;     \end{tabular}</span></span>
<span><span class="co">#&gt;     \end{adjustbox}</span></span>
<span><span class="co">#&gt;     \caption{Point estimates and $95\%$ confidence intervals for the GATEs. Leaves are sorted in increasing order of the GATEs. Additionally, differences in the GATEs across all pairs of leaves are displayed. p-values to test the null hypothesis that a single difference is zero are adjusted using Holm's procedure and reported in parenthesis under each point estimate.}</span></span>
<span><span class="co">#&gt;     \label{table:differences.gates}</span></span>
<span><span class="co">#&gt;     \end{table}</span></span>
<span><span class="co">#&gt; \endgroup</span></span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">results</span>, table <span class="op">=</span> <span class="st">"avg_char"</span><span class="op">)</span></span>
<span><span class="co">#&gt; \begingroup</span></span>
<span><span class="co">#&gt;   \setlength{\tabcolsep}{8pt}</span></span>
<span><span class="co">#&gt;   \renewcommand{\arraystretch}{1.1}</span></span>
<span><span class="co">#&gt;   \begin{table}[b!]</span></span>
<span><span class="co">#&gt;     \centering</span></span>
<span><span class="co">#&gt;     \begin{adjustbox}{width = 1\textwidth}</span></span>
<span><span class="co">#&gt;     \begin{tabular}{@{\extracolsep{5pt}}l c c c c c c c c }</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;       &amp; \multicolumn{2}{c}{\textit{Leaf 1}} &amp; \multicolumn{2}{c}{\textit{Leaf 2}} &amp; \multicolumn{2}{c}{\textit{Leaf 3}} &amp; \multicolumn{2}{c}{\textit{Leaf 4}} \\\cmidrule{2-3} \cmidrule{4-5} \cmidrule{6-7} \cmidrule{8-9} </span></span>
<span><span class="co">#&gt;       &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) &amp; Mean &amp; (S.D.) \\</span></span>
<span><span class="co">#&gt;       \addlinespace[2pt]</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex] </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \texttt{x1} &amp; 0.047 &amp; (0.041) &amp; -0.008 &amp; (0.031) &amp; 0.04 &amp; (0.041) &amp; 0.071 &amp; (0.055) \\ </span></span>
<span><span class="co">#&gt;       \texttt{x2} &amp; -1.368 &amp; (0.021) &amp; -0.177 &amp; (0.01) &amp; 0.743 &amp; (0.01) &amp; 1.71 &amp; (0.026) \\ </span></span>
<span><span class="co">#&gt;       \texttt{x3} &amp; 0.075 &amp; (0.043) &amp; -0.002 &amp; (0.03) &amp; 0.021 &amp; (0.042) &amp; 0.037 &amp; (0.06) \\ </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       \addlinespace[3pt]</span></span>
<span><span class="co">#&gt;       \\[-1.8ex]\hline</span></span>
<span><span class="co">#&gt;       \hline \\[-1.8ex]</span></span>
<span><span class="co">#&gt;     \end{tabular}</span></span>
<span><span class="co">#&gt;     \end{adjustbox}</span></span>
<span><span class="co">#&gt;     \caption{Average characteristics of units in each leaf, obtained by regressing each covariate on a set of dummies denoting leaf membership. Standard errors are estimated via the Eicker-Huber-White estimator. Leaves are sorted in increasing order of the GATEs.}</span></span>
<span><span class="co">#&gt;     \label{table:average.characteristics.leaves}</span></span>
<span><span class="co">#&gt;     \end{table}</span></span>
<span><span class="co">#&gt; \endgroup</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<ul>
<li><p>Athey, S., &amp; Imbens, G. W. (2016). <b>Recursive Partitioning
for Heterogeneous Causal Effects.</b> <i>Proceedings of the National
Academy of Sciences</i>, 113(27).
[<a href="https://www.pnas.org/doi/abs/10.1073/pnas.1510489113" class="external-link">paper</a>]</p></li>
<li><p>Athey, S., Tibshirani, J., &amp; Wager, S. (2019). <b>Generalized
Random Forests.</b> <i>Annals of Statistics</i>, 47(2).
[<a href="https://projecteuclid.org/euclid.aos/1547197251" class="external-link">paper</a>]</p></li>
<li><p>Chernozhukov, V., Demirer, M., Duflo, E., &amp; Fernandez-Val, I.
(2017). <b>Generic Machine Learning Inference on Heterogeneous Treatment
Effects in Randomized Experiments.</b> <i>National Bureau of Economic
Research</i>.
[<a href="https://www.nber.org/papers/w24678" class="external-link">paper</a>]</p></li>
<li><p>Di Francesco, R. (2022). <b>Aggregation Trees.</b> <i>CEIS
Research Paper, 546.</i>
[<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4304256" class="external-link">paper</a>]</p></li>
<li><p>Holm, S. (1979). <b>A Simple Sequentially Rejective Multiple Test
Procedure.</b> <i>Scandinavian Journal of Statistics</i>, 6(2).
[<a href="https://www.jstor.org/stable/4615733" class="external-link">paper</a>]</p></li>
<li><p>Semenova, V., &amp; Chernozhukov, V. (2021). <b>Debiased Machine
Learning of Conditional Average Treatment Effects and Other Causal
Functions.</b> <i>The Econometrics Journal</i>, 24(2).
[<a href="https://academic.oup.com/ectj/article/24/2/264/5899048" class="external-link">paper</a>]</p></li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Riccardo Di Francesco.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
