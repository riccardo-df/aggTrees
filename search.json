[{"path":"https://riccardo-df.github.io/aggTrees/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 aggTrees authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Short Tutorial","text":"tutorial, show typical usage package. illustration purposes, let us generate data:","code":"## Generate data. set.seed(1986)  n <- 5000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)"},{"path":"https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html","id":"constructing-the-sequence-of-groupings","dir":"Articles","previous_headings":"","what":"Constructing the Sequence of Groupings","title":"Short Tutorial","text":"construct sequence optimal groupings, first need estimate CATEs. use causal forest estimator. achieve valid inference GATEs, split sample training sample honest sample equal sizes. forest built using training sample. Now use build_aggtree function construct sequence groupings. function approximates estimated CATEs decision tree using training sample computes node predictions (.e., GATEs) using honest sample. build_aggtree allows user choose two GATE estimators: set method = \"raw\", GATEs estimated taking differences mean outcomes treated control units node. unbiased estimator () randomized experiments; set method = \"aipw\", GATEs estimated averaging doubly-robust scores (see Appendix ) node. unbiased estimator also observational studies particular conditions construction scores. doubly-robust scores can estimated separately passed scores argument. Otherwise, estimated internally. Notice use is_honest argument, logical vector denoting observations allocated honest sample. way, build_aggtree knows observations must used construct tree compute node predictions.","code":"## Sample split. splits <- sample_split(length(y), training_frac = 0.5) training_idx <- splits$training_idx honest_idx <- splits$honest_idx  y_tr <- y[training_idx] D_tr <- D[training_idx] X_tr <- X[training_idx, ]  y_hon <- y[honest_idx] D_hon <- D[honest_idx] X_hon <- X[honest_idx, ]  ## Estimate the CATEs. Use training sample. library(grf) forest <- causal_forest(X_tr, y_tr, D_tr)  cates <- predict(forest, X)$predictions ## Construct the sequence. Use doubly-robust scores. groupings <- build_aggtree(y, D, X, method = \"aipw\",                             cates = cates, is_honest = 1:length(y) %in% honest_idx)  ## Print. print(groupings) #> Honest estimates: TRUE  #> n= 2500  #>  #> node), split, n, deviance, yval #>       * denotes terminal node #>  #>  1) root 2500 2372.437000  0.04518749   #>    2) x2< 0.3646614 1615  614.394700 -0.55084130   #>      4) x2< -0.7479499 594   63.762530 -1.31435400   #>        8) x2< -1.438649 217    5.703318 -2.03895100 * #>        9) x2>=-1.438649 377   13.974630 -0.98914180 * #>      5) x2>=-0.7479499 1021   84.592370 -0.14006240   #>       10) x2< -0.3224095 345   11.004430 -0.38424370 * #>       11) x2>=-0.3224095 676   19.214170 -0.01797179 * #>    3) x2>=0.3646614 885  221.380400  1.06528900   #>      6) x2< 1.510563 714   58.170860  0.93028800   #>       12) x2< 0.7534031 301    7.964079  0.56146550 * #>       13) x2>=0.7534031 413    8.017662  1.22245000 * #>      7) x2>=1.510563 171   10.190770  1.78282800 *  ## Plot. plot(groupings) # Try also setting 'sequence = TRUE'."},{"path":"https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html","id":"further-analysis","dir":"Articles","previous_headings":"","what":"Further Analysis","title":"Short Tutorial","text":"Now whole sequence optimal groupings, can pick grouping associated preferred granularity level call inference_aggtree function. function following: gets standard errors GATEs estimating via OLS appropriate linear models using honest sample. choice linear model depends method used called build_aggtree (see Appendix ); tests null hypotheses differences GATEs across pairs groups equal zero. , account multiple hypotheses testing adjusting \\(p\\)-values using Holm’s procedure; computes average characteristics units group. report results, can print nice LATEX tables.","code":"## Inference with 4 groups. results <- inference_aggtree(groupings, n_groups = 4)  ## LATEX. print(results, table = \"diff\") #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.2} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 0.85\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c} #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex]  #>  #>       & \\textit{Leaf 1} & \\textit{Leaf 2} & \\textit{Leaf 3} & \\textit{Leaf 4} \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\multirow{2}{*}{GATEs} & -1.314 & -0.14 & 0.93 & 1.783 \\\\ #>       & [-1.49, -1.138] & [-0.262, -0.018] & [0.783, 1.077] & [1.487, 2.079] \\\\  #>  #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\textit{Leaf 1} & NA & NA & NA & NA \\\\ #>             & (NA) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 2} & 1.174 & NA & NA & NA \\\\ #>             & (0) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 3} & 2.245 & 1.07 & NA & NA \\\\ #>             & (0) & (0) & (NA) & (NA) \\\\  #>       \\textit{Leaf 4} & 3.097 & 1.923 & 0.853 & NA \\\\ #>             & (0) & (0) & (0) & (NA) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Point estimates and $95\\%$ confidence intervals for the GATEs. Leaves are sorted in increasing order of the GATEs. Additionally, differences in the GATEs across all pairs of leaves are displayed. p-values to test the null hypothesis that a single difference is zero are adjusted using Holm's procedure and reported in parenthesis under each point estimate.} #>     \\label{table:differences.gates} #>     \\end{table} #> \\endgroup  print(results, table = \"avg_char\") #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.1} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 1\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c c c c c } #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>       & \\multicolumn{2}{c}{\\textit{Leaf 1}} & \\multicolumn{2}{c}{\\textit{Leaf 2}} & \\multicolumn{2}{c}{\\textit{Leaf 3}} & \\multicolumn{2}{c}{\\textit{Leaf 4}} \\\\\\cmidrule{2-3} \\cmidrule{4-5} \\cmidrule{6-7} \\cmidrule{8-9}  #>       & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\texttt{x1} & 0.047 & (0.04) & -0.019 & (0.03) & 0.006 & (0.036) & -0.024 & (0.087) \\\\  #>       \\texttt{x2} & -1.309 & (0.021) & -0.161 & (0.01) & 0.854 & (0.012) & 1.933 & (0.033) \\\\  #>       \\texttt{x3} & 0.053 & (0.042) & -0.016 & (0.03) & 0.031 & (0.037) & 0.041 & (0.079) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Average characteristics of units in each leaf, obtained by regressing each covariate on a set of dummies denoting leaf membership. Standard errors are estimated via the Eicker-Huber-White estimator. Leaves are sorted in increasing order of the GATEs.} #>     \\label{table:average.characteristics.leaves} #>     \\end{table} #> \\endgroup"},{"path":"https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Short Tutorial","text":"point estimating linear models get standard errors GATEs. honesty condition, can use estimated standard errors conduct valid inference usual, e.g., constructing conventional confidence intervals. Honesty subsample-splitting technique requires different observations used form subgroups estimate GATEs. inference_aggtree always uses honest sample estimate linear models (unless called build_aggtree without using honesty settings). set method = \"raw\", inference_aggtree estimates via OLS following linear model: \\[\\begin{equation}     Y_i = \\sum_{l = 1}^{|\\mathcal{T_{\\alpha}}|} L_{, l} \\, \\gamma_l + \\sum_{l = 1}^{|\\mathcal{T}_{\\alpha}|} L_{, l} \\, D_i \\, \\beta_l + \\epsilon_i \\end{equation}\\] \\(|\\mathcal{T}_{\\alpha}|\\) number leaves particular tree \\(\\mathcal{T}_{\\alpha}\\), \\(L_{, l}\\) dummy variable equal one \\(\\)-th unit falls \\(l\\)-th leaf \\(\\mathcal{T}_{\\alpha}\\). Exploiting random assignment treatment, can show \\(\\beta_l\\) identifies GATE \\(l\\)-th leaf. honesty, OLS estimator \\(\\hat{\\beta}_l\\) \\(\\beta_l\\) root-\\(n\\) consistent asymptotically normal. set method = \"aipw\", inference_aggtree estimates via OLS following linear model: \\[\\begin{equation}     \\widehat{\\Gamma}_i = \\sum_{l = 1}^{|\\mathcal{T}_{\\alpha}|} L_{, l} \\, \\beta_l + \\epsilon_i \\end{equation}\\] \\(\\Gamma_i\\) following doubly-robust scores: \\[\\begin{equation*}     \\Gamma_i = \\mu \\left( 1, X_i \\right) - \\mu \\left( 0, X_i \\right) + \\frac{D_i \\left[ Y_i - \\mu \\left( 1, X_i \\right) \\right]}{p \\left( X_i \\right)}  - \\frac{ \\left( 1 - D_i \\right) \\left[ Y_i - \\mu \\left( 0, X_i \\right) \\right]}{1 - p \\left( X_i \\right)} \\end{equation*}\\] \\(\\mu \\left(D_i, X_i \\right) = \\mathbb{E} \\left[ Y_i | D_i, Z_i \\right]\\) conditional mean \\(Y_i\\) \\(p \\left( X_i \\right) = \\mathbb{P} \\left( D_i = 1 | X_i \\right)\\) propensity score. scores inherited scores used build_aggtree call. , can show \\(\\beta_l\\) identifies GATE \\(l\\)-th leaf, time even observational studies. honesty, OLS estimator \\(\\hat{\\beta}_l\\) \\(\\beta_l\\) root-\\(n\\) consistent asymptotically normal, provided \\(\\Gamma_i\\) cross-fitted product convergence rates estimators nuisance functions \\(\\mu \\left( \\cdot, \\cdot \\right)\\) \\(p \\left( \\cdot \\right)\\) faster \\(n^{1/2}\\).","code":""},{"path":"https://riccardo-df.github.io/aggTrees/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Riccardo Di Francesco. Author, maintainer.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Di Francesco R (2023). aggTrees: Aggregation Trees. R package version 2.0.0, https://riccardo-df.github.io/aggTrees/.","code":"@Manual{,   title = {aggTrees: Aggregation Trees},   author = {Riccardo {Di Francesco}},   year = {2023},   note = {R package version 2.0.0},   url = {https://riccardo-df.github.io/aggTrees/}, }"},{"path":"https://riccardo-df.github.io/aggTrees/index.html","id":"aggregation-trees-","dir":"","previous_headings":"","what":"Aggregation Trees","title":"Aggregation Trees","text":"R package implement aggregation trees, nonparametric approach discovering heterogeneous subgroups selection--observables framework. approach consists three steps: Estimate conditional average treatment effects (CATEs); Approximate CATEs decision tree; Prune tree. way, generate sequence groupings, one granularity level. resulting sequence nested sense subgroups formed given level granularity never broken coarser levels. guarantees consistency results across different granularity levels, generally considered basic requirement every classification system satisfy. Moreover, grouping features optimality property ensures loss explained heterogeneity resulting aggregation minimized. Given sequence groupings, can estimate group average treatment effects (GATEs) like. package supports two estimators, based differences mean outcomes treated control units (unbiased randomized experiments) sample averages doubly-robust scores (unbiased also observational studies). package also allows get standard errors GATEs estimating via OLS appropriate linear models. “honesty”” condition, can use estimated standard errors conduct valid inference GATEs usual, e.g., constructing conventional confidence intervals","code":""},{"path":"https://riccardo-df.github.io/aggTrees/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Aggregation Trees","text":"package can downloaded CRAN: Alternatively, current development version package can installed using devtools package:","code":"install.packages(\"aggTrees\") devtools::install_github(\"riccardo-df/aggTrees\") # run install.packages(\"devtools\") if needed."},{"path":"https://riccardo-df.github.io/aggTrees/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Aggregation Trees","text":"Please check package vignette short tutorial.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Aggregation Trees","text":"Athey, S., & Imbens, G. W. (2016). Recursive Partitioning Heterogeneous Causal Effects. Proceedings National Academy Sciences, 113(27). [paper] Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized Random Forests. Annals Statistics, 47(2). [paper] Chernozhukov, V., Demirer, M., Duflo, E., & Fernandez-Val, . (2017). Generic Machine Learning Inference Heterogeneous Treatment Effects Randomized Experiments. National Bureau Economic Research. [paper] Cotterman, R., & Peracchi, F. (1992). Classification aggregation: application industrial classification cps data. Journal Applied Econometrics, 7(1). [paper] Di Francesco, R. (2022). Aggregation Trees. CEIS Research Paper, 546. [paper] Holm, S. (1979). Simple Sequentially Rejective Multiple Test Procedure. Scandinavian Journal Statistics, 6(2). [paper] Semenova, V., & Chernozhukov, V. (2021). Debiased Machine Learning Conditional Average Treatment Effects Causal Functions. Econometrics Journal, 24(2). [paper]","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaves Average Characteristics — avg_characteristics_rpart","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"Computes average characteristics units leaf rpart object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"","code":"avg_characteristics_rpart(tree, X)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"tree rpart object. X Covariate matrix (intercept).","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"list storing regression lm_robust object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"avg_characteristics_rpart regresses covariate set dummies denoting leaf membership. way, get average characteristics units leaf, together standard error. Leaves ordered increasing order predictions (negative positive). Standard errors estimated via Eicker-Huber-White estimator.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/avg_characteristics_rpart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaves Average Characteristics — avg_characteristics_rpart","text":"","code":"## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Construct a tree. library(rpart) tree <- rpart(y ~ ., data = data.frame(\"y\" = y, X), maxdepth = 2)  ## Compute average characteristics in each leaf. results <- avg_characteristics_rpart(tree, X) results #> $x1 #>         Estimate Std. Error   t value      Pr(>|t|)   CI Lower   CI Upper  DF #> leaf1 -0.6842363 0.03891988 -17.58064  1.820282e-60 -0.7606107 -0.6078620 996 #> leaf2 -1.0285623 0.03511188 -29.29385 1.475196e-136 -1.0974641 -0.9596606 996 #> leaf3  0.9479987 0.04694932  20.19196  2.872890e-76  0.8558678  1.0401296 996 #> leaf4  0.6519292 0.03386953  19.24825  1.928781e-70  0.5854653  0.7183930 996 #>  #> $x2 #>         Estimate Std. Error   t value      Pr(>|t|)   CI Lower   CI Upper  DF #> leaf1 -1.0023930 0.03864401 -25.93915 9.332206e-114 -1.0782260 -0.9265599 996 #> leaf2  0.5961527 0.04565908  13.05661  4.435946e-36  0.5065537  0.6857517 996 #> leaf3 -0.9994408 0.04208617 -23.74749  3.871292e-99 -1.0820286 -0.9168531 996 #> leaf4  0.6490106 0.03296403  19.68845  3.822315e-73  0.5843237  0.7136976 996 #>  #> $x3 #>           Estimate Std. Error     t value  Pr(>|t|)    CI Lower   CI Upper  DF #> leaf1  0.034682951 0.06678296  0.51933835 0.6036402 -0.09636849 0.16573440 996 #> leaf2  0.004315809 0.06991988  0.06172506 0.9507942 -0.13289137 0.14152298 996 #> leaf3 -0.010503234 0.07545163 -0.13920486 0.8893164 -0.15856564 0.13755917 996 #> leaf4 -0.033976386 0.04994827 -0.68023146 0.4965160 -0.13199231 0.06403954 996 #>"},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Measures — balance_measures","title":"Balance Measures — balance_measures","text":"Compute several balance measures check whether covariate distributions balanced across treatment arms.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Measures — balance_measures","text":"","code":"balance_measures(X, D)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Measures — balance_measures","text":"X Covariate matrix (intercept). D Treatment assignment vector.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Measures — balance_measures","text":"Prints LATEX code console.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Measures — balance_measures","text":"covariate X, balance_measures computes sample averages standard deviations treatment arms. Additionally, two balance measures computed: Norm. Diff. Normalized differences, computed differences means covariate   across treatment arms, normalized sum within-arm variances. provide measure   discrepancy locations covariate distributions across treatment arms. Log S.D. Log ratio standard deviations computed logarithm ratio   within-arm standard deviations. provide measure   discrepancy dispersion covariate distributions across treatment arms. Compilation LATEX code requires following packages: booktabs, float, adjustbox.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Measures — balance_measures","text":"Elena Dal Torrione, Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/balance_measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Measures — balance_measures","text":"","code":"## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Print table. balance_measures(X, D) #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.1} #>   \\begin{table}[H] #>     \\centering #>     \\begin{adjustbox}{width = 0.75\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c c c} #>     \\\\[-1.8ex]\\hline #>     \\hline \\\\[-1.8ex] #>     & \\multicolumn{2}{c}{Treated} & \\multicolumn{2}{c}{Controls} & \\multicolumn{2}{c}{Overlap measures} \\\\ \\cmidrule{6-7} #>     & \\multicolumn{2}{c}{($n_t =  502 $)} & \\multicolumn{2}{c}{($n_c = 498 $)} & \\\\ \\cmidrule{2-5} #>     & Mean & (S.D.) & Mean & (S.D.) & $\\hat{\\Delta}_j$ & $\\hat{\\Gamma}_j$ \\\\ #>     \\addlinespace[2pt] #>     \\hline \\\\[-1.8ex]  #>  #>     \\texttt{x1} & 0.080 & (1.011) & 0.028 & (1.004) & 0.052 & 0.007 \\\\  #>     \\texttt{x2} & -0.005 & (1.026) & -0.009 & (0.999) & 0.003 & 0.027 \\\\  #>     \\texttt{x3} & -0.026 & (1.015) & 0.013 & (0.979) & -0.039 & 0.036 \\\\  #>  #>     \\addlinespace[3pt] #>     \\\\[-1.8ex]\\hline #>     \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Balance between treatment and control groups. The last two columns report the estimated normalized differences ($\\hat{\\Delta}_j$) and logarithms of the ratio of standard deviations ($\\hat{\\Gamma}_j$).} #>     \\label{table:descriptive.stats} #>     \\end{table} #> \\endgroup"},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregation Trees — build_aggtree","title":"Aggregation Trees — build_aggtree","text":"Nonparametric data-driven approach discovering heterogeneous subgroups selection--observables framework. approach constructs sequence groupings, one level granularity. Groupings nested feature optimality property. grouping, obtain point estimation standard errors group average treatment effects (GATEs). Additionally, assess whether systematic heterogeneity found testing hypotheses differences GATEs across pairs groups zero. Finally, investigate driving mechanisms effect heterogeneity computing average characteristics units group.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregation Trees — build_aggtree","text":"","code":"build_aggtree(   y,   D,   X,   honest_frac = 0.5,   method = \"aipw\",   scores = NULL,   cates = NULL,   is_honest = NULL,   ... )  inference_aggtree(object, n_groups)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregation Trees — build_aggtree","text":"y Outcome vector. D Treatment vector. X Covariate matrix (intercept). honest_frac Fraction observations allocated honest sample. method Either \"raw\" \"aipw\", controls node predictions computed. scores Optional, vector scores used computing node predictions. Useful save computational time scores already estimated. Ignored method == \"raw\". cates Optional, estimated CATEs. provided user, CATEs estimated internally via causal_forest. is_honest Logical vector denoting observations belong honest sample. Required cates argument used. ... arguments rpart.control. object aggTrees object. n_groups Number desired groups.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregation Trees — build_aggtree","text":"build_aggtree returns aggTrees object. inference_aggtree returns aggTrees.inference object, turn contains aggTrees object used call.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregation Trees — build_aggtree","text":"Aggregation trees three-step procedure. First, conditional average treatment effects (CATEs) estimated using estimator. Second, tree grown approximate CATEs. Third, tree pruned derive nested sequence optimal groupings, one granularity level. level granularity, can obtain point estimation inference GATEs. implement methodology, user can rely two core functions handle various steps.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"constructing-the-sequence-of-groupings","dir":"Reference","previous_headings":"","what":"Constructing the Sequence of Groupings","title":"Aggregation Trees — build_aggtree","text":"build_aggtree constructs sequence groupings (.e., tree) estimate GATEs node. GATEs can estimated several ways. controlled method argument. method == \"raw\", compute difference mean outcomes treated control observations node. unbiased estimator randomized experiment. method == \"aipw\", construct doubly-robust scores average node. unbiased also observational studies. Honest regression forests 5-fold cross fitting used estimate propensity score conditional mean function outcome (unless user specifies argument scores). user can provide vector estimated CATEs via cates argument. , user needs specify logical vector denote observations belong honest sample. honesty desired, is_honest must vector FALSEs. vector CATEs provided, estimated internally via causal_forest.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"gates-estimation-and-inference","dir":"Reference","previous_headings":"","what":"GATEs Estimation and Inference","title":"Aggregation Trees — build_aggtree","text":"inference_aggtree takes input aggTrees object constructed build_aggtree. , desired granularity level, chosen via n_groups argument, provides point estimation standard errors GATEs. Additionally, performs hypothesis testing assess whether find systematic heterogeneity computes average characteristics units group investigate driving mechanisms.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"point-estimates-and-standard-errors-for-the-gates","dir":"Reference","previous_headings":"","what":"Point estimates and standard errors for the GATEs","title":"Aggregation Trees — build_aggtree","text":"GATEs standard errors obtained fitting appropriate linear model. method == \"raw\", estimate via OLS following: $$Y_i = \\sum_{l = 1}^{|T|} L_{, l} \\gamma_l + \\sum_{l = 1}^{|T|} L_{, l} D_i \\beta_l + \\epsilon_i$$ L_{, l} dummy variable equal one -th unit falls l-th group, |T| number groups. treatment randomly assigned, one can show betas identify GATE group. However, true observational studies due selection treatment. case, user expected use method == \"aipw\" calling build_aggtree. case, inference_aggtree uses scores following regression: $$score_i = \\sum_{l = 1}^{|T|} L_{, l} \\beta_l + \\epsilon_i$$ way, betas identify GATEs. Regardless method, standard errors estimated via Eicker-Huber-White estimator.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"hypothesis-testing","dir":"Reference","previous_headings":"","what":"Hypothesis testing","title":"Aggregation Trees — build_aggtree","text":"inference_aggtree uses standard errors obtained fitting linear models test hypotheses GATEs different across pairs leaves. , adjust p-values account multiple hypotheses testing using Holm's procedure.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"average-characteristics","dir":"Reference","previous_headings":"","what":"Average Characteristics","title":"Aggregation Trees — build_aggtree","text":"inference_aggtree regresses covariate set dummies denoting group membership. way, get average characteristics units leaf, together standard error. Leaves ordered increasing order predictions (negative positive). Standard errors estimated via Eicker-Huber-White estimator.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"caution-on-inference","dir":"Reference","previous_headings":"","what":"Caution on Inference","title":"Aggregation Trees — build_aggtree","text":"Regardless chosen method, functions estimate GATEs, linear models, average characteristics units group using observations honest sample. honest sample empty (happens user either sets honest_frac = 0 passes vector FALSEs is_honest calling build_aggtree), data used construct tree used estimate quantities. fine prediction invalidates inference.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Aggregation Trees — build_aggtree","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Aggregation Trees — build_aggtree","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/build_aggtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregation Trees — build_aggtree","text":"","code":"# \\donttest{ ## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Construct sequence of groupings. CATEs estimated internally. groupings <- build_aggtree(y, D, X, method = \"aipw\")  ## Alternatively, we can estimate the CATEs and pass them. splits <- sample_split(length(y), training_frac = 0.5) training_idx <- splits$training_idx honest_idx <- splits$honest_idx  y_tr <- y[training_idx] D_tr <- D[training_idx] X_tr <- X[training_idx, ]  y_hon <- y[honest_idx] D_hon <- D[honest_idx] X_hon <- X[honest_idx, ]  library(grf) forest <- causal_forest(X_tr, y_tr, D_tr) # Use training sample. cates <- predict(forest, X)$predictions  groupings <- build_aggtree(y, D, X, method = \"aipw\", cates = cates,                            is_honest = 1:length(y) %in% honest_idx)  ## We have compatibility with generic S3-methods. summary(groupings) #> Honest estimates: TRUE  #> Call: #> rpart::rpart(formula = cates ~ ., data = data.frame(cates = cates[training_idx],  #>     X_tr), method = \"anova\", model = TRUE, control = rpart::rpart.control(...)) #>   n= 500  #>  #>           CP nsplit  rel error     xerror        xstd #> 1 0.83058853      0 1.00000000 1.00771257 0.030825922 #> 2 0.09344721      1 0.16941147 0.17190900 0.007887736 #> 3 0.04000645      2 0.07596426 0.07819024 0.006270086 #> 4 0.01000000      3 0.03595781 0.03824223 0.002039752 #>  #> Variable importance #> x2 x3 x1  #> 92  4  4  #>  #> Node number 1: 500 observations,    complexity param=0.8305885 #>   mean=-0.06414735, MSE=1.060902  #>   left son=2 (230 obs) right son=3 (270 obs) #>   Primary splits: #>       x2 < -0.07518198 to the left,  improve=0.83058850, (0 missing) #>       x1 < -0.207075   to the left,  improve=0.01980168, (0 missing) #>       x3 < -0.9775529  to the left,  improve=0.01388725, (0 missing) #>   Surrogate splits: #>       x3 < -0.983981   to the left,  agree=0.560, adj=0.043, (0 split) #>       x1 < -0.207075   to the left,  agree=0.558, adj=0.039, (0 split) #>  #> Node number 2: 230 observations,    complexity param=0.04000645 #>   mean=-0.789146, MSE=0.1300297  #>   left son=4 (169 obs) right son=5 (61 obs) #>   Primary splits: #>       x2 < -0.4126471  to the left,  improve=0.70958610, (0 missing) #>       x1 < 0.1943697   to the left,  improve=0.09276113, (0 missing) #>       x3 < -0.61261    to the left,  improve=0.01080878, (0 missing) #>   Surrogate splits: #>       x1 < -1.889246   to the right, agree=0.743, adj=0.033, (0 split) #>       x3 < 2.095613    to the left,  agree=0.739, adj=0.016, (0 split) #>  #> Node number 3: 270 observations,    complexity param=0.09344721 #>   mean=0.5839575, MSE=0.2220655  #>   left son=6 (122 obs) right son=7 (148 obs) #>   Primary splits: #>       x2 < 0.5478927   to the left,  improve=0.82673610, (0 missing) #>       x3 < 0.4544582   to the left,  improve=0.03798430, (0 missing) #>       x1 < 1.302729    to the left,  improve=0.01857262, (0 missing) #>   Surrogate splits: #>       x3 < -1.130523   to the left,  agree=0.593, adj=0.098, (0 split) #>       x1 < 0.09411584  to the left,  agree=0.570, adj=0.049, (0 split) #>  #> Node number 4: 169 observations #>   mean=-1.055781, MSE=0.02613966  #>  #> Node number 5: 61 observations #>   mean=0.1095144, MSE=0.06996318  #>  #> Node number 6: 122 observations #>   mean=-0.08652797, MSE=0.03845698  #>  #> Node number 7: 148 observations #>   mean=1.19614, MSE=0.03849155  #>  print(groupings) #> Honest estimates: TRUE  #> n= 500  #>  #> node), split, n, deviance, yval #>       * denotes terminal node #>  #> 1) root 500 530.451100 -0.06414735   #>   2) x2< -0.07518198 230  29.906820 -0.78914600   #>     4) x2< -0.4126471 169   4.417603 -1.05578100 * #>     5) x2>=-0.4126471 61   4.267754  0.10951440 * #>   3) x2>=-0.07518198 270  59.957670  0.58395750   #>     6) x2< 0.5478927 122   4.691751 -0.08652797 * #>     7) x2>=0.5478927 148   5.696749  1.19614000 * plot(groupings) # Try also setting 'sequence = TRUE'.   ## To predict, do the following. tree <- subtree(groupings$tree, cv = TRUE) # Select by cross-validation. head(predict(tree, data.frame(X))) #>          1          2          3          4          5          6  #>  0.1095144 -1.0557814  1.1961398  1.1961398 -1.0557814 -1.0557814   ## Inference with 4 groups. results <- inference_aggtree(groupings, n_groups = 4)  summary(results$model) # Coefficient of leafk is GATE in k-th leaf. #>  #> Call: #> estimatr::lm_robust(formula = scores ~ 0 + leaf, data = data.frame(scores = scores,  #>     leaf = leaves), se_type = \"HC1\") #>  #> Standard error type:  HC1  #>  #> Coefficients: #>       Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF #> leaf1 -1.05578     0.1551 -6.8089 2.851e-11  -1.3604  -0.7511 496 #> leaf2 -0.08653     0.1873 -0.4619 6.444e-01  -0.4546   0.2815 496 #> leaf3  0.10951     0.2805  0.3904 6.964e-01  -0.4416   0.6606 496 #> leaf4  1.19614     0.1994  5.9984 3.846e-09   0.8043   1.5879 496 #>  #> Multiple R-squared:  0.1476 ,\tAdjusted R-squared:  0.1407  #> F-statistic: 20.68 on 4 and 496 DF,  p-value: 8.936e-16  results$gates_diff_pairs$gates_diff # GATEs differences. #>           leaf1     leaf2    leaf3 leaf4 #> leaf1        NA        NA       NA    NA #> leaf2 0.9692535        NA       NA    NA #> leaf3 1.1652958 0.1960423       NA    NA #> leaf4 2.2519213 1.2826678 1.086625    NA results$gates_diff_pairs$holm_pvalues # leaves 1-2 not statistically different. #>              [,1]         [,2]        [,3] [,4] #> [1,]           NA           NA          NA   NA #> [2,] 3.094972e-04           NA          NA   NA #> [3,] 9.180598e-04 5.613635e-01          NA   NA #> [4,] 5.617761e-17 1.784486e-05 0.003377922   NA  ## LATEX. print(results, table = \"diff\") #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.2} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 0.85\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c} #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex]  #>  #>       & \\textit{Leaf 1} & \\textit{Leaf 2} & \\textit{Leaf 3} & \\textit{Leaf 4} \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\multirow{2}{*}{GATEs} & -1.056 & -0.087 & 0.11 & 1.196 \\\\ #>       & [-1.36, -0.752] & [-0.454, 0.28] & [-0.439, 0.659] & [0.806, 1.586] \\\\  #>  #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\textit{Leaf 1} & NA & NA & NA & NA \\\\ #>             & (NA) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 2} & 0.969 & NA & NA & NA \\\\ #>             & (0) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 3} & 1.165 & 0.196 & NA & NA \\\\ #>             & (0.001) & (0.561) & (NA) & (NA) \\\\  #>       \\textit{Leaf 4} & 2.252 & 1.283 & 1.087 & NA \\\\ #>             & (0) & (0) & (0.003) & (NA) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Point estimates and $95\\%$ confidence intervals for the GATEs. Leaves are sorted in increasing order of the GATEs. Additionally, differences in the GATEs across all pairs of leaves are displayed. p-values to test the null hypothesis that a single difference is zero are adjusted using Holm's procedure and reported in parenthesis under each point estimate.} #>     \\label{table:differences.gates} #>     \\end{table} #> \\endgroup  #>  print(results, table = \"avg_char\")# } #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.1} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 1\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c c c c c } #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>       & \\multicolumn{2}{c}{\\textit{Leaf 1}} & \\multicolumn{2}{c}{\\textit{Leaf 2}} & \\multicolumn{2}{c}{\\textit{Leaf 3}} & \\multicolumn{2}{c}{\\textit{Leaf 4}} \\\\\\cmidrule{2-3} \\cmidrule{4-5} \\cmidrule{6-7} \\cmidrule{8-9}  #>       & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\texttt{x1} & 0.025 & (0.072) & 0.035 & (0.096) & -0.179 & (0.133) & 0.086 & (0.082) \\\\  #>       \\texttt{x2} & -1.131 & (0.042) & 0.209 & (0.016) & -0.237 & (0.014) & 1.101 & (0.04) \\\\  #>       \\texttt{x3} & -0.009 & (0.071) & 0.088 & (0.092) & -0.066 & (0.13) & -0.047 & (0.092) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Average characteristics of units in each leaf, obtained by regressing each covariate on a set of dummies denoting leaf membership. Standard errors are estimated via the Eicker-Huber-White estimator. Leaves are sorted in increasing order of the GATEs.} #>     \\label{table:average.characteristics.leaves} #>     \\end{table} #> \\endgroup  #>"},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"Obtains point estimates standard errors group average treatment effects (GATEs), groups correspond leaves rpart object. Additionally, performs hypothesis testing.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"","code":"causal_ols_rpart(tree, y, D, X, method = \"aipw\", scores = NULL)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"tree rpart object. y Outcome vector. D Treatment assignment vector X Covariate matrix (intercept). method Either \"raw\" \"aipw\", defines outcome used regression. scores Optional, vector scores used regression. Useful save computational time scores already estimated. Ignored method == \"raw\".","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"list storing: model model fitted get point estimates standard errors GATEs, lm_robust object. gates_diff_pairs Results testing whether GATEs differ across pairs leaves. list storing GATEs differences p-values adjusted using Holm's procedure (check p.adjust). NULL tree consists root . scores Vector doubly robust scores. NULL method == 'raw'.","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"point-estimates-and-standard-errors-for-the-gates","dir":"Reference","previous_headings":"","what":"Point estimates and standard errors for the GATEs","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"GATEs standard errors obtained fitting appropriate linear model. method == \"raw\", estimate via OLS following: $$Y_i = \\sum_{l = 1}^{|T|} L_{, l} \\gamma_l + \\sum_{l = 1}^{|T|} L_{, l} D_i \\beta_l + \\epsilon_i$$ L_{, l} dummy variable equal one -th unit falls l-th leaf tree, |T| number groups. treatment randomly assigned, one can show betas identify GATE leaf. However, true observational studies due selection treatment. case, user expected use method == \"aipw\" run following regression: $$score_i = \\sum_{l = 1}^{|T|} L_{, l} \\beta_l + \\epsilon_i$$ score_i doubly-robust scores constructed via honest regression forests 5-fold cross fitting (unless user specifies argument scores). way, betas identify GATEs. Regardless method, standard errors estimated via Eicker-Huber-White estimator. tree consists root , causal_ols_rpart regresses y constant D method == \"raw\", regresses doubly-robust scores constant method == \"aipw\". way, get estimate overall average treatment effect.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"hypothesis-testing","dir":"Reference","previous_headings":"","what":"Hypothesis testing","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"causal_ols_rpart uses standard errors obtained fitting linear models test hypotheses GATEs different across pairs leaves. , adjust p-values account multiple hypotheses testing using Holm's procedure.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"caution-on-inference","dir":"Reference","previous_headings":"","what":"Caution on Inference","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"\"honesty\" necessary requirement get valid inference. Thus, observations y, D, X must used construct tree scores.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/causal_ols_rpart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation and Inference about the GATEs with rpart Objects — causal_ols_rpart","text":"","code":"## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Split the sample. splits <- sample_split(length(y), training_frac = 0.5) training_idx <- splits$training_idx honest_idx <- splits$honest_idx  y_tr <- y[training_idx] D_tr <- D[training_idx] X_tr <- X[training_idx, ]  y_hon <- y[honest_idx] D_hon <- D[honest_idx] X_hon <- X[honest_idx, ]  ## Construct a tree using training sample. library(rpart) tree <- rpart(y ~ ., data = data.frame(\"y\" = y_tr, X_tr), maxdepth = 2)  ## Estimate GATEs in each node (internal and terminal) using honest sample. results <- causal_ols_rpart(tree, y_hon, D_hon, X_hon, method = \"raw\")  summary(results$model) # Coefficient of leafk:D is GATE in k-th leaf. #>  #> Call: #> estimatr::lm_robust(formula = y ~ 0 + leaf + D:leaf, data = data.frame(y = y,  #>     leaf = leaves, D = D), se_type = \"HC1\") #>  #> Standard error type:  HC1  #>  #> Coefficients: #>          Estimate Std. Error  t value  Pr(>|t|) CI Lower CI Upper  DF #> leaf1   -0.036996    0.12751 -0.29014 7.718e-01  -0.2875   0.2135 492 #> leaf2    0.477702    0.19133  2.49681 1.286e-02   0.1018   0.8536 492 #> leaf3   -0.001513    0.09483 -0.01595 9.873e-01  -0.1878   0.1848 492 #> leaf4    0.814105    0.21189  3.84217 1.379e-04   0.3978   1.2304 492 #> leaf1:D -1.508032    0.20002 -7.53928 2.293e-13  -1.9010  -1.1150 492 #> leaf2:D -1.110904    0.27575 -4.02865 6.497e-05  -1.6527  -0.5691 492 #> leaf3:D  0.555771    0.14146  3.92889 9.755e-05   0.2778   0.8337 492 #> leaf4:D  1.003031    0.35536  2.82259 4.957e-03   0.3048   1.7012 492 #>  #> Multiple R-squared:  0.2944 ,\tAdjusted R-squared:  0.2829  #> F-statistic: 25.03 on 8 and 492 DF,  p-value: < 2.2e-16  results$gates_diff_pair$gates_diff # GATEs differences. #>           leaf1    leaf2     leaf3 leaf4 #> leaf1        NA       NA        NA    NA #> leaf2 0.3971281       NA        NA    NA #> leaf3 2.0638027 1.666675        NA    NA #> leaf4 2.5110626 2.113935 0.4472599    NA results$gates_diff_pair$holm_pvalues # leaves 1-2 and 3-4 not statistically different. #>              [,1]         [,2]      [,3] [,4] #> [1,]           NA           NA        NA   NA #> [2,] 4.856388e-01           NA        NA   NA #> [3,] 2.413800e-15 4.669980e-07        NA   NA #> [4,] 7.666574e-09 1.015841e-05 0.4856388   NA"},{"path":"https://riccardo-df.github.io/aggTrees/reference/descriptive_arm.html","id":null,"dir":"Reference","previous_headings":"","what":"Descriptive Statistics by Treatment Arm — descriptive_arm","title":"Descriptive Statistics by Treatment Arm — descriptive_arm","text":"Computes sample averages standard deviations covariates across treatment arms.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/descriptive_arm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Descriptive Statistics by Treatment Arm — descriptive_arm","text":"","code":"descriptive_arm(X, D)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/descriptive_arm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Descriptive Statistics by Treatment Arm — descriptive_arm","text":"X Covariate matrix (intercept). D Treatment assignment vector.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/descriptive_arm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Descriptive Statistics by Treatment Arm — descriptive_arm","text":"4xp array, storing desired statistics.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/descriptive_arm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Descriptive Statistics by Treatment Arm — descriptive_arm","text":"Sample means standard deviations across treatment arms first, useful insight assess covariate balance.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly-Robust Scores — dr_scores","title":"Doubly-Robust Scores — dr_scores","text":"Constructs doubly-robust scores via K-fold cross-fitting.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly-Robust Scores — dr_scores","text":"","code":"dr_scores(y, D, X, k = 5)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly-Robust Scores — dr_scores","text":"y Outcome vector. D Treatment assignment vector. X Covariate matrix (intercept). k Number folds.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly-Robust Scores — dr_scores","text":"vector scores.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly-Robust Scores — dr_scores","text":"Honest regression forests used estimate propensity score conditional mean function outcome.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/dr_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Doubly-Robust Scores — dr_scores","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":null,"dir":"Reference","previous_headings":"","what":"GATE Estimation with rpart Objects — estimate_rpart","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"Replaces node predictions rpart object using external data estimate group average treatment effects (GATEs).","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"","code":"estimate_rpart(tree, y, D, X, method = \"aipw\", scores = NULL)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"tree rpart object. y Outcome vector. D Treatment assignment vector. X Covariate matrix (intercept). method Either \"raw\" \"aipw\", controls node predictions replaced. scores Optional, vector scores used replacing node predictions. Useful save computational time scores already estimated. Ignored method == \"raw\".","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"tree node predictions replaced, rpart object, scores (method == \"raw\", NULL).","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"method == \"raw\", estimate_rpart replaces node predictions differences sample average observed outcomes treated units sample average observed outcomes control units node, unbiased estimator GATEs assignment treatment randomized. method == \"aipw\", estimate_rpart replaces node predictions sample averages doubly-robust scores node. valid estimator GATEs observational studies. Honest regression forests 5-fold cross fitting used estimate propensity score conditional mean function outcome (unless user specifies argument scores). estimate_rpart allows user implement \"honest\" estimation. observations y, D X used construct tree, new predictions honest sense Athey Imbens (2016). get standard errors tree's estimates, please use causal_ols_rpart.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/estimate_rpart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GATE Estimation with rpart Objects — estimate_rpart","text":"","code":"## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Split the sample. splits <- sample_split(length(y), training_frac = 0.5) training_idx <- splits$training_idx honest_idx <- splits$honest_idx  y_tr <- y[training_idx] D_tr <- D[training_idx] X_tr <- X[training_idx, ]  y_hon <- y[honest_idx] D_hon <- D[honest_idx] X_hon <- X[honest_idx, ]  ## Construct a tree using training sample. library(rpart) tree <- rpart(y ~ ., data = data.frame(\"y\" = y_tr, X_tr), maxdepth = 2)  ## Estimate GATEs in each node (internal and terminal) using honest sample. new_tree <- estimate_rpart(tree, y_hon, D_hon, X_hon, method = \"raw\") new_tree$tree #> n= 500  #>  #> node), split, n, deviance, yval #>       * denotes terminal node #>  #> 1) root 500 848.77870 -0.1196941   #>   2) x2< -0.2670246 208 294.70990 -1.3627760   #>     4) x1< 0.111117 116 149.74660 -1.5080320 * #>     5) x1>=0.111117 92 108.62540 -1.1109040 * #>   3) x2>=-0.2670246 292 425.26540  0.5981272   #>     6) x1< 1.135506 231 289.47460  0.5557710 * #>     7) x1>=1.135506 61  70.06308  1.0030310 *"},{"path":"https://riccardo-df.github.io/aggTrees/reference/expand_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Covariate Matrix Expansion — expand_df","title":"Covariate Matrix Expansion — expand_df","text":"Expands covariate matrix, adding interactions polynomials. particularly useful penalized regressions.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/expand_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Covariate Matrix Expansion — expand_df","text":"","code":"expand_df(X, int_order = 2, poly_order = 4, threshold = 0)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/expand_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Covariate Matrix Expansion — expand_df","text":"X Covariate matrix (intercept). int_order Order interactions added. Set equal one interactions desired. poly_order Order polynomials added. Set equal one polynomials desired. threshold Drop binary variables representing less threshold% population. Useful speed computation.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/expand_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Covariate Matrix Expansion — expand_df","text":"expanded covariate matrix, data frame.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/expand_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Covariate Matrix Expansion — expand_df","text":"expand_df assumes categorical variables coded factors. Also, missing values allowed.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Leaves — get_leaves","title":"Number of Leaves — get_leaves","text":"Extracts number leaves rpart object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Leaves — get_leaves","text":"","code":"get_leaves(tree)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Leaves — get_leaves","text":"tree rpart object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Leaves — get_leaves","text":"number leaves.","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Number of Leaves — get_leaves","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/get_leaves.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Leaves — get_leaves","text":"","code":"## Generate data. set.seed(1986)  n <- 3000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k))  y <- exp(X[, 1]) + 2 * X[, 2] * X[, 2] > 0 + rnorm(n)  ## Construct tree. library(rpart) tree <- rpart(y ~ ., data = data.frame(y, X))  ## Extract number of leaves. n_leaves <- get_leaves(tree) n_leaves #> [1] 8"},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaf Membership — leaf_membership","title":"Leaf Membership — leaf_membership","text":"Constructs variable encodes leaf rpart object units given data frame fall.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaf Membership — leaf_membership","text":"","code":"leaf_membership(tree, X)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaf Membership — leaf_membership","text":"tree rpart object. X Covariate matrix (intercept).","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaf Membership — leaf_membership","text":"factor whose levels denote leaf unit falls. Leaves ordered increasing order predictions (negative positive).","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Leaf Membership — leaf_membership","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/leaf_membership.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaf Membership — leaf_membership","text":"","code":"## Generate data. set.seed(1986)  n <- 3000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k))  y <- exp(X[, 1]) + 2 * X[, 2] * X[, 2] > 0 + rnorm(n)  ## Construct tree. library(rpart) tree <- rpart(y ~ ., data = data.frame(y, X))  ## Extract number of leaves. leaves_factor <- leaf_membership(tree, X) head(leaves_factor) #> 1 2 3 4 5 6  #> 5 7 7 2 7 2  #> Levels: 1 2 3 4 5 6 7 8"},{"path":"https://riccardo-df.github.io/aggTrees/reference/log_ratio_sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Log Ratio of Standard Deviations — log_ratio_sd","title":"Log Ratio of Standard Deviations — log_ratio_sd","text":"Computes measure difference dispersion covariate distributions across treatment arms.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/log_ratio_sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log Ratio of Standard Deviations — log_ratio_sd","text":"","code":"log_ratio_sd(X, D)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/log_ratio_sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log Ratio of Standard Deviations — log_ratio_sd","text":"X Covariate matrix (intercept). D Treatment assignment vector.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/log_ratio_sd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log Ratio of Standard Deviations — log_ratio_sd","text":"1xp data frame storing logarithm ratio standard deviations covariate.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/log_ratio_sd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log Ratio of Standard Deviations — log_ratio_sd","text":"Log ratio standard deviations computed logarithm ratio within-arm standard deviations.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":null,"dir":"Reference","previous_headings":"","what":"Node Membership — node_membership","title":"Node Membership — node_membership","text":"Constructs binary variable encodes whether observation falls particular node rpart object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Node Membership — node_membership","text":"","code":"node_membership(tree, X, node)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Node Membership — node_membership","text":"tree rpart object. X Covariate matrix (intercept). node Number node.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Node Membership — node_membership","text":"Logical vector denoting whether observation X falls node.","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Node Membership — node_membership","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/node_membership.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Node Membership — node_membership","text":"","code":"## Generate data. set.seed(1986)  n <- 3000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k))  y <- exp(X[, 1]) + 2 * X[, 2] * X[, 2] > 0 + rnorm(n)  ## Construct tree. library(rpart) tree <- rpart(y ~ ., data = data.frame(y, X))  ## Extract number of leaves. is_in_third_node <- node_membership(tree, X, 3) head(is_in_third_node) #> [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE"},{"path":"https://riccardo-df.github.io/aggTrees/reference/normalized_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalized Differences — normalized_diff","title":"Normalized Differences — normalized_diff","text":"Computes measure difference locations covariate distributions across treatment arms.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/normalized_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalized Differences — normalized_diff","text":"","code":"normalized_diff(X, D)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/normalized_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalized Differences — normalized_diff","text":"X Covariate matrix (intercept). D Treatment assignment vector.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/normalized_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalized Differences — normalized_diff","text":"1xp data frame storing normalized difference covariate.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/normalized_diff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalized Differences — normalized_diff","text":"Normalized differences computed difference means covariate across treatment arms, normalized sum within-arm variances.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for aggTrees Objects — plot.aggTrees","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"Plots aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"","code":"# S3 method for aggTrees plot(x, leaves = get_leaves(x$tree), sequence = FALSE, ...)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"x aggTrees object. leaves Number leaves desired tree. can used plot subtrees. sequence TRUE, whole sequence optimal groupings displayed short animation. ... arguments prp.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"Plots aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"Nodes colored using diverging palette. Nodes predictions smaller ATE (.e., root prediction) colored blue shades, nodes predictions larger ATE colored red shades. Moreover, predictions distant absolute value ATE get darker shades. way, immediate understanding groups extreme GATEs.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/plot.aggTrees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for aggTrees Objects — plot.aggTrees","text":"","code":"# \\donttest{ ## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Construct sequence of groupings. CATEs estimated internally, groupings <- build_aggtree(y, D, X, method = \"aipw\")  ## Plot. plot(groupings)  plot(groupings, leaves = 3)  plot(groupings, sequence = TRUE)# }"},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for aggTrees Objects — print.aggTrees","title":"Print Method for aggTrees Objects — print.aggTrees","text":"Prints aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for aggTrees Objects — print.aggTrees","text":"","code":"# S3 method for aggTrees print(x, ...)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for aggTrees Objects — print.aggTrees","text":"x aggTrees object. ... arguments passed methods.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for aggTrees Objects — print.aggTrees","text":"Prints aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for aggTrees Objects — print.aggTrees","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for aggTrees Objects — print.aggTrees","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"Prints aggTrees.inference object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"","code":"# S3 method for aggTrees.inference print(x, table = \"avg_char\", ...)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"x aggTrees.inference object. table Either \"avg_char\" \"diff\", controls table must produced. ... arguments passed methods.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"Prints LATEX code.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"description table provided caption. covariates may feature zero variation leaf. generally happens dummy variables used split nodes. case, table == \"avg_char\" warning message produced displaying names covariates zero variation one leaves. user correct table removing associated standard errors. Compilation LATEX code requires following packages: booktabs, float, adjustbox, multirow.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/print.aggTrees.inference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Method for aggTrees.inference Objects — print.aggTrees.inference","text":"","code":"# \\donttest{ ## Generate data. set.seed(1986)  n <- 1000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k)) D <- rbinom(n, size = 1, prob = 0.5) mu0 <- 0.5 * X[, 1] mu1 <- 0.5 * X[, 1] + X[, 2] y <- mu0 + D * (mu1 - mu0) + rnorm(n)  ## Construct sequence of groupings. CATEs estimated internally, groupings <- build_aggtree(y, D, X, method = \"aipw\")  ## Analyze results with 4 groups. results <- inference_aggtree(groupings, n_groups = 4)  ## Print results. print(results, table = \"diff\") #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.2} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 0.85\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c} #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex]  #>  #>       & \\textit{Leaf 1} & \\textit{Leaf 2} & \\textit{Leaf 3} & \\textit{Leaf 4} \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\multirow{2}{*}{GATEs} & -1.454 & -0.442 & 0.097 & 1.443 \\\\ #>       & [-1.781, -1.127] & [-1.03, 0.146] & [-0.222, 0.416] & [1.086, 1.8] \\\\  #>  #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\textit{Leaf 1} & NA & NA & NA & NA \\\\ #>             & (NA) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 2} & 1.012 & NA & NA & NA \\\\ #>             & (0.007) & (NA) & (NA) & (NA) \\\\  #>       \\textit{Leaf 3} & 1.552 & 0.54 & NA & NA \\\\ #>             & (0) & (0.115) & (NA) & (NA) \\\\  #>       \\textit{Leaf 4} & 2.897 & 1.885 & 1.346 & NA \\\\ #>             & (0) & (0) & (0) & (NA) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Point estimates and $95\\%$ confidence intervals for the GATEs. Leaves are sorted in increasing order of the GATEs. Additionally, differences in the GATEs across all pairs of leaves are displayed. p-values to test the null hypothesis that a single difference is zero are adjusted using Holm's procedure and reported in parenthesis under each point estimate.} #>     \\label{table:differences.gates} #>     \\end{table} #> \\endgroup  #>  print(results, table = \"avg_char\")# } #> \\begingroup #>   \\setlength{\\tabcolsep}{8pt} #>   \\renewcommand{\\arraystretch}{1.1} #>   \\begin{table}[b!] #>     \\centering #>     \\begin{adjustbox}{width = 1\\textwidth} #>     \\begin{tabular}{@{\\extracolsep{5pt}}l c c c c c c c c } #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>       & \\multicolumn{2}{c}{\\textit{Leaf 1}} & \\multicolumn{2}{c}{\\textit{Leaf 2}} & \\multicolumn{2}{c}{\\textit{Leaf 3}} & \\multicolumn{2}{c}{\\textit{Leaf 4}} \\\\\\cmidrule{2-3} \\cmidrule{4-5} \\cmidrule{6-7} \\cmidrule{8-9}  #>       & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) & Mean & (S.D.) \\\\ #>       \\addlinespace[2pt] #>       \\hline \\\\[-1.8ex]  #>  #>       \\texttt{x1} & -0.018 & (0.073) & 0.051 & (0.179) & -0.021 & (0.079) & -0.023 & (0.082) \\\\  #>       \\texttt{x2} & -1.056 & (0.044) & -0.261 & (0.013) & 0.226 & (0.017) & 1.272 & (0.045) \\\\  #>       \\texttt{x3} & 0.043 & (0.075) & -0.114 & (0.154) & -0.149 & (0.081) & 0.029 & (0.088) \\\\  #>  #>       \\addlinespace[3pt] #>       \\\\[-1.8ex]\\hline #>       \\hline \\\\[-1.8ex] #>     \\end{tabular} #>     \\end{adjustbox} #>     \\caption{Average characteristics of units in each leaf, obtained by regressing each covariate on a set of dummies denoting leaf membership. Standard errors are estimated via the Eicker-Huber-White estimator. Leaves are sorted in increasing order of the GATEs.} #>     \\label{table:average.characteristics.leaves} #>     \\end{table} #> \\endgroup  #>"},{"path":"https://riccardo-df.github.io/aggTrees/reference/rename_latex.html","id":null,"dir":"Reference","previous_headings":"","what":"Renaming Variables for LATEX Usage — rename_latex","title":"Renaming Variables for LATEX Usage — rename_latex","text":"Renames variables character \"_\" used, causes clashes LATEX. Useful phased print method.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/rename_latex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Renaming Variables for LATEX Usage — rename_latex","text":"","code":"rename_latex(names)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/rename_latex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Renaming Variables for LATEX Usage — rename_latex","text":"names string vector.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/rename_latex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Renaming Variables for LATEX Usage — rename_latex","text":"renamed string vector. Strings \"_\" found modified rename_latex.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/sample_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Splitting — sample_split","title":"Sample Splitting — sample_split","text":"Splits sample training honest subsamples.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/sample_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Splitting — sample_split","text":"","code":"sample_split(n, training_frac = 0.5)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/sample_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Splitting — sample_split","text":"n Size sample split. training_frac Fraction units training sample.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/sample_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Splitting — sample_split","text":"list storing indexes two different subsamples.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/sample_split.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample Splitting — sample_split","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtree — subtree","title":"Subtree — subtree","text":"Extracts subtree user-specified number leaves rpart object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtree — subtree","text":"","code":"subtree(tree, leaves = NULL, cv = FALSE)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtree — subtree","text":"tree rpart object. leaves Number leaves desired subtree. cv TRUE, leaves ignored cross-validation criterion used select partition.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtree — subtree","text":"subtree, rpart object.","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Subtree — subtree","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/subtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subtree — subtree","text":"","code":"## Generate data. set.seed(1986)  n <- 3000 k <- 3  X <- matrix(rnorm(n * k), ncol = k) colnames(X) <- paste0(\"x\", seq_len(k))  y <- exp(X[, 1]) + 2 * X[, 2] * X[, 2] > 0 + rnorm(n)  ## Construct tree. library(rpart) tree <- rpart(y ~ ., data = data.frame(y, X), cp = 0)  ## Extract subtree. sub_tree <- subtree(tree, leaves = 4) sub_tree_cv <- subtree(tree, cv = TRUE)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for aggTrees Objects — summary.aggTrees","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"Summarizes aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"","code":"# S3 method for aggTrees summary(object, ...)"},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"object aggTrees object. ... arguments passed methods.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"Prints summary aggTrees object.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"R Di Francesco (2022). Aggregation Trees. CEIS Research Paper, 546. doi:10.2139/ssrn.4304256 .","code":""},{"path":[]},{"path":"https://riccardo-df.github.io/aggTrees/reference/summary.aggTrees.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary Method for aggTrees Objects — summary.aggTrees","text":"Riccardo Di Francesco","code":""},{"path":"https://riccardo-df.github.io/aggTrees/news/index.html","id":"version-200","dir":"Changelog","previous_headings":"","what":"version 2.0.0","title":"version 2.0.0","text":"CRAN release: 2023-02-21 Updated hypothesis testing procedure. Improved LATEX output.","code":""},{"path":"https://riccardo-df.github.io/aggTrees/news/index.html","id":"version-100","dir":"Changelog","previous_headings":"","what":"version 1.0.0","title":"version 1.0.0","text":"CRAN release: 2023-02-09","code":""},{"path":[]}]
